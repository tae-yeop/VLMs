{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61aa1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f208f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A\")\n",
    "ANN_DIR    = ROOT / \"Annotations\" \n",
    "IMG_DIR    = ROOT / \"JPEGImages\" \n",
    "MAX_LEN  = 5       # '00013' 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d884794",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for xml_path in ANN_DIR.glob(\"*.xml\"):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    raw = root.findtext(\"filename\") or \"\"\n",
    "    stem = Path(raw).stem # '9.jpg' → '9',  '1'→'1'\n",
    "    stem = stem.zfill(MAX_LEN)  # '9' → '00009', '1' → '00001'\n",
    "    img_path = IMG_DIR / f'PartA_{stem}.jpg'\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        print(f\"Image {img_path} does not exist, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    person_cnt = sum(1 for obj in root.findall(\"object\")\n",
    "                       if obj.findtext(\"name\") == \"person\")\n",
    "\n",
    "    pairs.append((str(img_path), person_cnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e7f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00000.jpg',\n",
       "  81),\n",
       " ('/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00001.jpg',\n",
       "  5),\n",
       " ('/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00002.jpg',\n",
       "  29)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22811f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = (\n",
    "    \"You are CrowdCountGPT. \"\n",
    "    \"When counting people, reply with ONLY the number (no words, no punctuation).\"\n",
    ")\n",
    "PROMPT = (\"Count all the people in the image and answer with *only* the number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3b1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conv(path, cnt):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": [{\"type\": \"text\", \"text\": SYSTEM}]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Count all the people in the image.\"},\n",
    "                {\"type\": \"image\", \"image\": path}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": [{\"type\": \"text\", \"text\": str(cnt)}]\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe359fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_list([make_conv(p, c) for p, c in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a593daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd1e65c",
   "metadata": {},
   "source": [
    "### collate 사전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2920576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b18208e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['messages'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4539bdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': [{'image': None,\n",
       "    'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).',\n",
       "    'type': 'text'}],\n",
       "  'role': 'system'},\n",
       " {'content': [{'image': None,\n",
       "    'text': 'Count all the people in the image.',\n",
       "    'type': 'text'},\n",
       "   {'image': '/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00000.jpg',\n",
       "    'text': None,\n",
       "    'type': 'image'}],\n",
       "  'role': 'user'},\n",
       " {'content': [{'image': None, 'text': '81', 'type': 'text'}],\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(2)[:2]['messages'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aeec66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_batch_samples = dataset.select(range(2)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a28ba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': [{'image': None,\n",
       "     'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).',\n",
       "     'type': 'text'}],\n",
       "   'role': 'system'},\n",
       "  {'content': [{'image': None,\n",
       "     'text': 'Count all the people in the image.',\n",
       "     'type': 'text'},\n",
       "    {'image': '/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00000.jpg',\n",
       "     'text': None,\n",
       "     'type': 'image'}],\n",
       "   'role': 'user'},\n",
       "  {'content': [{'image': None, 'text': '81', 'type': 'text'}],\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_batch_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "425e9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "images = []\n",
    "examples = dataset.select(range(2)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vision_info(messages):\n",
    "    image_inputs = []\n",
    "\n",
    "    for msg in messages:\n",
    "        for element in msg.get(\"content\", []):\n",
    "            if not isinstance(element, dict):\n",
    "                continue\n",
    "\n",
    "            if element.get(\"type\") == \"image\":\n",
    "                img_obj = element.get(\"image\", element)   \n",
    "\n",
    "                # 문자열이면 파일 경로 → 열기\n",
    "                if isinstance(img_obj, (str, Path)):\n",
    "                    img_obj = Image.open(img_obj)\n",
    "\n",
    "                # 최종 RGB 변환\n",
    "                image_inputs.append(img_obj.convert(\"RGB\"))\n",
    "\n",
    "    return image_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "import io, os\n",
    "\n",
    "def hf_img_to_pil(img_dict):\n",
    "    \"\"\"\n",
    "    HF Image feature -> PIL.Image\n",
    "    \"\"\"\n",
    "    # 1) bytes가 있으면 바로\n",
    "    if img_dict.get(\"bytes\") is not None:\n",
    "        return PILImage.open(io.BytesIO(img_dict[\"bytes\"]))\n",
    "    # 2) path가 있으면 경로에서 로드\n",
    "    if img_dict.get(\"path\") is not None and os.path.exists(img_dict[\"path\"]):\n",
    "        return PILImage.open(img_dict[\"path\"])\n",
    "    return None  # 둘 다 없으면 실패\n",
    "\n",
    "def process_vision_info(messages):\n",
    "    # 하나의 conversation 데이터에 있는 list of dict를 처리\n",
    "    imgs = []\n",
    "    for msg in messages:                       # message = {'role':..., 'content': [...]}\n",
    "        for elem in msg.get(\"content\", []):    # elem = dict\n",
    "            # ① 이미지 타입인지 필터\n",
    "            if elem.get(\"type\") != \"image\":\n",
    "                continue\n",
    "            img_obj = elem.get(\"image\")\n",
    "            # ② 실제 이미지 객체가 있는지 확인\n",
    "            if img_obj is None:\n",
    "                continue\n",
    "            # ③ HF Image dict → PIL 변환\n",
    "            if isinstance(img_obj, dict):\n",
    "                img_obj = hf_img_to_pil(img_obj)\n",
    "            if isinstance(img_obj, PILImage.Image):\n",
    "                imgs.append(img_obj.convert(\"RGB\"))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be3c5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': [{'image': None, 'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).', 'type': 'text'}], 'role': 'system'}, {'content': [{'image': None, 'text': 'Count all the people in the image.', 'type': 'text'}, {'image': '/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00000.jpg', 'text': None, 'type': 'image'}], 'role': 'user'}, {'content': [{'image': None, 'text': '81', 'type': 'text'}], 'role': 'assistant'}]\n",
      "[{'content': [{'image': None, 'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).', 'type': 'text'}], 'role': 'system'}, {'content': [{'image': None, 'text': 'Count all the people in the image.', 'type': 'text'}, {'image': '/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00001.jpg', 'text': None, 'type': 'image'}], 'role': 'user'}, {'content': [{'image': None, 'text': '5', 'type': 'text'}], 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    image_inputs = process_vision_info(example[\"messages\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0a50d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': [{'image': None,\n",
       "    'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).',\n",
       "    'type': 'text'}],\n",
       "  'role': 'system'},\n",
       " {'content': [{'image': None,\n",
       "    'text': 'Count all the people in the image.',\n",
       "    'type': 'text'},\n",
       "   {'image': '/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00000.jpg',\n",
       "    'text': None,\n",
       "    'type': 'image'}],\n",
       "  'role': 'user'},\n",
       " {'content': [{'image': None, 'text': '81', 'type': 'text'}],\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b1a342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "import io, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c88e73fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': None, 'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).', 'type': 'text'}\n",
      "{'image': None, 'text': 'Count all the people in the image.', 'type': 'text'}\n",
      "{'image': '/purestorage/AILAB/AI_1/tyk/3_CUProjects/language_model/VLM/gemma3/finetune_crowd/SCUT_HEAD_Part_A/JPEGImages/PartA_00000.jpg', 'text': None, 'type': 'image'}\n",
      "<class 'str'>\n",
      "dsad\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1070x594 at 0x7FD2CF544F10>\n",
      "{'image': None, 'text': '81', 'type': 'text'}\n"
     ]
    }
   ],
   "source": [
    "image_inputs = []\n",
    "for msg in examples[0][\"messages\"]:\n",
    "    for element in msg.get(\"content\", []):\n",
    "        print(element)\n",
    "        if element.get(\"type\") != \"image\":\n",
    "            continue\n",
    "        img_obj = element.get(\"image\")\n",
    "\n",
    "        if img_obj is None:\n",
    "            continue\n",
    "        \n",
    "        print(type(img_obj))\n",
    "        if isinstance(img_obj, str):\n",
    "            print('dsad')\n",
    "            img_obj = PILImage.open(img_obj)\n",
    "\n",
    "        print(img_obj)\n",
    "        image_inputs.append(img_obj.convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecac01c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81986c",
   "metadata": {},
   "source": [
    "### Test dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6232451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from PIL import Image # 이미지 파일 존재 여부 및 유효성 검사를 위해 import\n",
    "\n",
    "def create_image_count_list(base_path):\n",
    "    \"\"\"\n",
    "    주어진 기본 경로에서 이미지와 Ground Truth 데이터를 찾아 리스트를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): 'images'와 'ground_truth' 폴더를 포함하는 상위 경로.\n",
    "                         예: '/purestorage/AILAB/AI_4/byko/VLM/dataset/ShanghaiTech_Crowd_Counting_Dataset/part_B_final/test_data/'\n",
    "\n",
    "    Returns:\n",
    "        list: 각 딕셔너리가 'path' (이미지 경로)와 'count' (사람 수)를 포함하는 리스트.\n",
    "              오류가 발생한 파일은 포함되지 않습니다.\n",
    "    \"\"\"\n",
    "    image_folder = os.path.join(base_path, 'images')\n",
    "    gt_folder = os.path.join(base_path, 'ground_truth')\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    # images 폴더의 모든 .jpg 파일 목록을 가져옵니다.\n",
    "    image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.jpg')])\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        \n",
    "        # 이미지 파일이 실제로 존재하는지 확인\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"경고: 이미지를 찾을 수 없습니다: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # PIL을 사용하여 이미지가 유효한지 간단히 확인\n",
    "            Image.open(img_path).close()\n",
    "        except Exception as e:\n",
    "            print(f\"경고: 유효하지 않은 이미지 파일입니다 ({img_path}): {e}\")\n",
    "            continue\n",
    "\n",
    "        # 해당 이미지에 대한 .mat 파일 이름 추론 (예: IMG_1.jpg -> GT_IMG_1.mat)\n",
    "        # 파일명에서 'IMG_' 부분을 유지하고, 확장자를 '.mat'으로 변경합니다.\n",
    "        # ShanghaiTech Part_B의 경우 IMG_X.jpg -> GT_IMG_X.mat 패턴을 따릅니다.\n",
    "        # 확장자를 제거하고 'GT_'를 붙인 후 '.mat'을 붙입니다.\n",
    "        base_name = os.path.splitext(img_file)[0] # IMG_1\n",
    "        mat_file_name = f\"GT_{base_name}.mat\" # GT_IMG_1.mat\n",
    "        mat_path = os.path.join(gt_folder, mat_file_name)\n",
    "\n",
    "        # .mat 파일이 존재하는지 확인\n",
    "        if not os.path.exists(mat_path):\n",
    "            print(f\"경고: 해당 Ground Truth .mat 파일을 찾을 수 없습니다: {mat_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # .mat 파일 로드\n",
    "            mat = sio.loadmat(mat_path)\n",
    "            \n",
    "            # 사람 수 추출 로직 (ShanghaiTech Part_B 데이터셋 구조에 따름)\n",
    "            # 'image_info' -> [0][0][0][0][0] -> points (N, 2) 배열\n",
    "            # 이 경로는 데이터셋마다 다를 수 있으므로, 에러 발생 시 mat.keys() 등으로 구조를 확인해야 합니다.\n",
    "            image_info = mat[\"image_info\"]\n",
    "            points = image_info[0][0][0][0][0]\n",
    "            \n",
    "            person_count = len(points)\n",
    "\n",
    "            data_list.append({\n",
    "                'path': img_path,\n",
    "                'count': person_count\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"경고: .mat 파일 처리 중 오류 발생 ({mat_path}): {e}\")\n",
    "            continue\n",
    "            \n",
    "    return data_list\n",
    "\n",
    "# 사용할 테스트 데이터 기본 경로\n",
    "test_data_path = '/purestorage/AILAB/AI_4/byko/VLM/dataset/ShanghaiTech_Crowd_Counting_Dataset/part_B_final/test_data/'\n",
    "\n",
    "# 함수 호출하여 리스트 생성\n",
    "test_dataset_list = create_image_count_list(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95488fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/purestorage/AILAB/AI_4/byko/VLM/dataset/ShanghaiTech_Crowd_Counting_Dataset/part_B_final/test_data/images/IMG_1.jpg',\n",
       " 'count': 23}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9d35598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test_dataset = Dataset.from_list([make_conv(example['path'], example['count']) for example in test_dataset_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fa5f215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': [{'image': None,\n",
       "     'text': 'You are CrowdCountGPT. When counting people, reply with ONLY the number (no words, no punctuation).',\n",
       "     'type': 'text'}],\n",
       "   'role': 'system'},\n",
       "  {'content': [{'image': None,\n",
       "     'text': 'Count all the people in the image.',\n",
       "     'type': 'text'},\n",
       "    {'image': '/purestorage/AILAB/AI_4/byko/VLM/dataset/ShanghaiTech_Crowd_Counting_Dataset/part_B_final/test_data/images/IMG_1.jpg',\n",
       "     'text': None,\n",
       "     'type': 'image'}],\n",
       "   'role': 'user'},\n",
       "  {'content': [{'image': None, 'text': '23', 'type': 'text'}],\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8e47d",
   "metadata": {},
   "source": [
    "### 합치고 푸시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c751e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "my_dataset_dict = DatasetDict({\n",
    "    'train': dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f87f67f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 316\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6229883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e780aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeb2185831e47f38bbb6b23898766d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af57f4770194508a4ac9b690f118848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0759363aea4bf9b4fb619431f60bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62644d3618a049c5a9d1d945786b54ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70c022de9944635ab672b972312f5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ty-kim/crowd_count/commit/84194efed201ea7a94238e67b4dbbdaee3776f86', commit_message='Upload dataset', commit_description='', oid='84194efed201ea7a94238e67b4dbbdaee3776f86', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ty-kim/crowd_count', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ty-kim/crowd_count'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, create_repo\n",
    "\n",
    "\n",
    "hf_token = \"\"\n",
    "login(token=hf_token)\n",
    "\n",
    "create_repo(\"ty-kim/crowd_count\", repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "# push to hub\n",
    "my_dataset_dict.push_to_hub(\"ty-kim/crowd_count\") # max_shard_size=\"500MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec92dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 결과 출력 (예시)\n",
    "print(f\"\\n총 생성된 데이터 항목 수: {len(test_dataset_list)}\")\n",
    "if test_dataset_list:\n",
    "    print(\"첫 5개 데이터 항목:\")\n",
    "    for i, item in enumerate(test_dataset_list[:5]):\n",
    "        print(f\"{i+1}: {item}\")\n",
    "else:\n",
    "    print(\"생성된 데이터 항목이 없습니다. 경로와 파일 구조를 확인해주세요.\")\n",
    "\n",
    "# 데이터셋의 일부 경로를 확인하여 파일이 실제로 존재하는지 최종 검증\n",
    "if test_dataset_list:\n",
    "    example_path = test_dataset_list[0]['path']\n",
    "    if os.path.exists(example_path):\n",
    "        print(f\"\\n예시 이미지 파일이 존재합니다: {example_path}\")\n",
    "    else:\n",
    "        print(f\"\\n경고: 예시 이미지 파일이 존재하지 않습니다. 경로를 다시 확인해주세요: {example_path}\")\n",
    "\n",
    "# 데이터셋 리스트는 이제 make_conv 함수에 전달될 수 있는 형식입니다.\n",
    "# make_conv(item['path'], item['count']) for item in test_dataset_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
